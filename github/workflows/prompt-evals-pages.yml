name: live-model-evals-to-pages

on:
  workflow_dispatch:
    inputs:
      title:
        description: "Report title (optional)"
        required: false
        default: "Prompt Evaluation Report"
  schedule:
    - cron: "0 6 * * *"  # daily 06:00 UTC

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  evals:
    if: ${{ secrets.OPENAI_API_KEY != '' }}
    runs-on: ubuntu-latest
    env:
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install deps
        run: |
          python -m pip install -U pip
          pip install -r requirements.txt
          pip install openai || true

      - name: Run evals (generates eval_report.md)
        run: |
          python scripts/eval_prompts.py
          test -f eval_report.md

      - name: Build docs site (from eval_report.md)
        run: |
          mkdir -p site
          ts="$(date -u +'%Y-%m-%d %H:%M UTC')"
          echo "# ${{ github.event.inputs.title || 'Prompt Evaluation Report' }}" > site/index.md
          echo "" >> site/index.md
          echo "_Run: **${ts}**, Commit: \`${GITHUB_SHA::7}\`_" >> site/index.md
          echo "" >> site/index.md
          cat eval_report.md >> site/index.md

      - name: Configure Pages
        uses: actions/configure-pages@v5

      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: site

  deploy:
    needs: evals
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - id: deployment
        uses: actions/deploy-pages@v4
